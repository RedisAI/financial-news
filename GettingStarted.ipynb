{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get 300 Financial News Headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "headlines_df = pd.read_csv('data/300_stock_headlines.csv')\n",
    "headlines_df.drop('Unnamed: 0.1', axis=1, inplace=True)\n",
    "headlines_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "headlines_df.reset_index()\n",
    "headlines_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate Financial Sentiment for each headline\n",
    "Using a pre-trained model fine-tuned on financial news/report data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate financial sentiment for each headline\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "nlp = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer)\n",
    "headlines = headlines_df[\"headline\"].tolist()\n",
    "\n",
    "#get financial sentiment for all headlines\n",
    "results = nlp(headlines)\n",
    "\n",
    "#show results for first 2 headlines\n",
    "print(results[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Join Financial Sentiment and Headline into a single Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put headlines and financial sentiment in 1 dataframe\n",
    "sentiment_df = pd.DataFrame(results)\n",
    "sentiment_df.reset_index()\n",
    "\n",
    "result_df = pd.concat([headlines_df, sentiment_df],axis=1)\n",
    "#show the first 10 rows \n",
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate Embeddings for each headline\n",
    "Using a HuggingFace Sentence Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate embeddings (vectors) for each headline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-distilroberta-v1')\n",
    "headline_vectors = [ model.encode(sentence) for sentence in result_df['headline']]\n",
    "#check how many dimensions in a single vector \n",
    "headline_vectors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Connect to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to redis\n",
    "\n",
    "from redis import Redis\n",
    "import redisearch\n",
    "\n",
    "host = 'vecsim'\n",
    "port = 6379\n",
    "redis_conn = Redis(host = host, port = port)\n",
    "print ('Connected to redis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Utility functions to load data into Redis \n",
    "We'll be loading into a \"hash\" structure (a table-like structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load articles into redis hash\n",
    "import numpy as np\n",
    "def load_vectors(client:Redis, headlines_df, vector_data,vector_field_name):\n",
    "    #pipeline the 300 articles in one go\n",
    "    p = client.pipeline(transaction=False)\n",
    "    for index, row in headlines_df.iterrows():    \n",
    "        #hash key\n",
    "        key='article:'+ str(index)\n",
    "        #hash fields\n",
    "        headline=row['headline']\n",
    "        url=row['url']\n",
    "        publisher=row['publisher']\n",
    "        date=row['date']\n",
    "        label=row['label']\n",
    "        score=row['score']\n",
    "        headline_vector = vector_data[index].astype(np.float32).tobytes()\n",
    "        headline_data_mapping ={'headline':headline,'url':url,'publisher':publisher,'label':label,'score':score, vector_field_name:headline_vector}\n",
    "        \n",
    "        p.hset(key,mapping=headline_data_mapping)\n",
    "    p.execute()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. More Utility Functions to Define vector indexes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Functions to Create Indexes on Vector field\n",
    "\n",
    "def create_bf_index (redis_conn,index_name,vector_field_name,number_of_vectors, vector_dimensions=768, distance_metric='L2'):\n",
    "    bf_index = redisearch.Client(index_name, conn=redis_conn)\n",
    "    bf_index.redis.execute_command(\"FT.CREATE\", index_name, \"SCHEMA\",vector_field_name, \"VECTOR\", \"FLAT\", \"8\", \"TYPE\", \"FLOAT32\", \"DIM\", vector_dimensions, \"DISTANCE_METRIC\", distance_metric, \"INITIAL_CAP\", number_of_vectors)\n",
    "    return bf_index\n",
    "\n",
    "def create_hnsw_index (redis_conn,index_name,vector_field_name,number_of_vectors, vector_dimensions=768, distance_metric='L2',M=40,EF=200):\n",
    "    hnsw_index = redisearch.Client(index_name, conn=redis_conn)\n",
    "    hnsw_index.redis.execute_command(\"FT.CREATE\", index_name, \"SCHEMA\", vector_field_name, \"VECTOR\", \"HNSW\", \"12\", \"TYPE\", \"FLOAT32\", \"DIM\", vector_dimensions, \"DISTANCE_METRIC\", distance_metric,  \"INITIAL_CAP\", number_of_vectors, \"M\", M, \"EF\", EF)\n",
    "    return hnsw_index\n",
    "\n",
    "def delete_index(vector_index):\n",
    "    delete_data(vector_index.redis)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Utility Functions to Query a vector index in Redis\n",
    "One function to query brute-force index and another to query an HNSW index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Functions to Perform Similarity Search\n",
    "\n",
    "def find_similar_bf(headline_q, query_encoder, vector_index,vector_field_name, topK=5):\n",
    "    #vectorize the query\n",
    "    query_vector = query_encoder.encode(headline_q).astype(np.float32).tobytes()\n",
    "    #prepare the query\n",
    "    q = redisearch.Query(f'(*)=>[TOP_K $K @{vector_field_name} $BLOB AS vector_score]').sort_by('vector_score').paging(0,topK).return_fields('vector_score','score','headline','label')\n",
    "    #Execute the query\n",
    "    results = vector_index.search(q, query_params = {'BLOB': query_vector, 'K':topK})\n",
    "    return results \n",
    "\n",
    "def find_similar_hnsw(headline_q, query_encoder, vector_index,vector_field_name, topK=5,EF=5):\n",
    "    #vectorize the query\n",
    "    query_vector = query_encoder.encode(headline_q).astype(np.float32).tobytes()\n",
    "    #prepare the query\n",
    "    q = redisearch.Query(f'(*)=>[TOP_K $K @{vector_field_name} $BLOB EF_RUNTIME $EF AS vector_score]').sort_by('vector_score').paging(0,topK).return_fields('vector_score','score','headline','label')    #Execute the query\n",
    "    results = vector_index.search(q, query_params = {'BLOB': query_vector, 'K':topK, 'EF':EF})\n",
    "    return results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Finally Load the Data into Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brute-Force - Load and Index article & vector Data\n",
    "NUMBER_ARTICLES = 300\n",
    "VECTOR_FIELD_NAME = 'headline_vector'\n",
    "redis_conn.flushall()\n",
    "bf_index = create_bf_index(redis_conn,'bf_index',VECTOR_FIELD_NAME,NUMBER_ARTICLES,768,'L2')\n",
    "load_vectors(bf_index.redis,result_df,headline_vectors,VECTOR_FIELD_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Query for similarity on the Brute-force index\n",
    "Get Top5 most semantically similar headlines to a given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query for similarity\n",
    "\n",
    "new_headline='bearish conditions ahead'\n",
    "\n",
    "results = find_similar_bf (new_headline,model,bf_index,VECTOR_FIELD_NAME,5)\n",
    "for doc in results.docs:\n",
    "    print ('***************Product  found ************')\n",
    "    #this must be a bug, I get the the headline by retrieving the \"vector score\" field!?\n",
    "    print ('headline = ' + doc.headline)\n",
    "    print ('label = ' + doc.label)\n",
    "    \n",
    "    print ('id = ' + doc.id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.docs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
