{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get 300 Financial News Headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agilent Technologies Announces Pricing of $5…… Million of Senior Notes</td>\n",
       "      <td>http://www.gurufocus.com/news/1153187/agilent-technologies-announces-pricing-of-500-million-of-s...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's in the Cards?</td>\n",
       "      <td>http://www.zacks.com/stock/news/931205/agilent-a-gears-up-for-q2-earnings-whats-in-the-cards?cid...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>2020-05-18 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquidation of Six Exchange-Traded Funds</td>\n",
       "      <td>http://www.gurufocus.com/news/1138923/jp-morgan-asset-management-announces-liquidation-of-six-ex...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys Agilent Technologies Inc, The Howard Hughes Corp, ...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138704/pershing-square-capital-management-lp-buys-agilent-technol...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden Ticket at LabCentral</td>\n",
       "      <td>http://www.gurufocus.com/news/1134012/agilent-awards-trilogy-sciences-with-a-golden-ticket-at-la...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-12 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              headline  \\\n",
       "0                               Agilent Technologies Announces Pricing of $5…… Million of Senior Notes   \n",
       "1                                           Agilent (A) Gears Up for Q2 Earnings: What's in the Cards?   \n",
       "2                      J.P. Morgan Asset Management Announces Liquidation of Six Exchange-Traded Funds   \n",
       "3  Pershing Square Capital Management, L.P. Buys Agilent Technologies Inc, The Howard Hughes Corp, ...   \n",
       "4                                   Agilent Awards Trilogy Sciences with a Golden Ticket at LabCentral   \n",
       "\n",
       "                                                                                                   url  \\\n",
       "0  http://www.gurufocus.com/news/1153187/agilent-technologies-announces-pricing-of-500-million-of-s...   \n",
       "1  http://www.zacks.com/stock/news/931205/agilent-a-gears-up-for-q2-earnings-whats-in-the-cards?cid...   \n",
       "2  http://www.gurufocus.com/news/1138923/jp-morgan-asset-management-announces-liquidation-of-six-ex...   \n",
       "3  http://www.gurufocus.com/news/1138704/pershing-square-capital-management-lp-buys-agilent-technol...   \n",
       "4  http://www.gurufocus.com/news/1134012/agilent-awards-trilogy-sciences-with-a-golden-ticket-at-la...   \n",
       "\n",
       "   publisher                 date stock  \n",
       "0  GuruFocus  2020-06-01 00:00:00     A  \n",
       "1      Zacks  2020-05-18 00:00:00     A  \n",
       "2  GuruFocus  2020-05-15 00:00:00     A  \n",
       "3  GuruFocus  2020-05-15 00:00:00     A  \n",
       "4  GuruFocus  2020-05-12 00:00:00     A  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "headlines_df = pd.read_csv('data/300_stock_headlines.csv')\n",
    "headlines_df.drop('Unnamed: 0.1', axis=1, inplace=True)\n",
    "headlines_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "headlines_df.reset_index()\n",
    "headlines_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate Financial Sentiment for each headline\n",
    "Using a pre-trained model fine-tuned on financial news/report data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 16:56:34.963982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-10 16:56:34.964040: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3070d5da88ca41449b655da88b8da0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/533 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73927386e2a442d89213e12aafa792fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/419M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60335ad590f848ca9c1dd9793655909c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/221k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'neutral', 'score': 0.9999771118164062}, {'label': 'neutral', 'score': 0.999295711517334}]\n"
     ]
    }
   ],
   "source": [
    "#Calculate financial sentiment for each headline\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "nlp = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer)\n",
    "headlines = headlines_df[\"headline\"].tolist()\n",
    "\n",
    "#get financial sentiment for all headlines\n",
    "results = nlp(headlines)\n",
    "\n",
    "#show results for first 2 headlines\n",
    "print(results[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Join Financial Sentiment and Headline into a single Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agilent Technologies Announces Pricing of $5…… Million of Senior Notes</td>\n",
       "      <td>http://www.gurufocus.com/news/1153187/agilent-technologies-announces-pricing-of-500-million-of-s...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's in the Cards?</td>\n",
       "      <td>http://www.zacks.com/stock/news/931205/agilent-a-gears-up-for-q2-earnings-whats-in-the-cards?cid...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>2020-05-18 00:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquidation of Six Exchange-Traded Funds</td>\n",
       "      <td>http://www.gurufocus.com/news/1138923/jp-morgan-asset-management-announces-liquidation-of-six-ex...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys Agilent Technologies Inc, The Howard Hughes Corp, ...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138704/pershing-square-capital-management-lp-buys-agilent-technol...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden Ticket at LabCentral</td>\n",
       "      <td>http://www.gurufocus.com/news/1134012/agilent-awards-trilogy-sciences-with-a-golden-ticket-at-la...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-12 00:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.971711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              headline  \\\n",
       "0                               Agilent Technologies Announces Pricing of $5…… Million of Senior Notes   \n",
       "1                                           Agilent (A) Gears Up for Q2 Earnings: What's in the Cards?   \n",
       "2                      J.P. Morgan Asset Management Announces Liquidation of Six Exchange-Traded Funds   \n",
       "3  Pershing Square Capital Management, L.P. Buys Agilent Technologies Inc, The Howard Hughes Corp, ...   \n",
       "4                                   Agilent Awards Trilogy Sciences with a Golden Ticket at LabCentral   \n",
       "\n",
       "                                                                                                   url  \\\n",
       "0  http://www.gurufocus.com/news/1153187/agilent-technologies-announces-pricing-of-500-million-of-s...   \n",
       "1  http://www.zacks.com/stock/news/931205/agilent-a-gears-up-for-q2-earnings-whats-in-the-cards?cid...   \n",
       "2  http://www.gurufocus.com/news/1138923/jp-morgan-asset-management-announces-liquidation-of-six-ex...   \n",
       "3  http://www.gurufocus.com/news/1138704/pershing-square-capital-management-lp-buys-agilent-technol...   \n",
       "4  http://www.gurufocus.com/news/1134012/agilent-awards-trilogy-sciences-with-a-golden-ticket-at-la...   \n",
       "\n",
       "   publisher                 date stock     label     score  \n",
       "0  GuruFocus  2020-06-01 00:00:00     A   neutral  0.999977  \n",
       "1      Zacks  2020-05-18 00:00:00     A   neutral  0.999296  \n",
       "2  GuruFocus  2020-05-15 00:00:00     A   neutral  0.999535  \n",
       "3  GuruFocus  2020-05-15 00:00:00     A   neutral  0.999965  \n",
       "4  GuruFocus  2020-05-12 00:00:00     A  positive  0.971711  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Put headlines and financial sentiment in 1 dataframe\n",
    "sentiment_df = pd.DataFrame(results)\n",
    "sentiment_df.reset_index()\n",
    "\n",
    "result_df = pd.concat([headlines_df, sentiment_df],axis=1)\n",
    "#show the first 10 rows \n",
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate Embeddings for each headline\n",
    "Using a HuggingFace Sentence Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66c52a8c4744def8c20aeafa99cbf04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/737 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bc39d6665f4ca6b97aa91894e97665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98877958da97410ebaec6648c0542d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febe76b0c28541bc9b7ffd1e8f0166d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f56cdd8caa4b85b4d8779ec372f1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/15.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6692497929104e97ab900d8759f8ce17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acb3a44a10b41efbaa680e7112ce180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1b9a0f42b544a6ba1e6ac3cc2d0d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4049b9fed94317b1d26bac4c2f459a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c75a78d59c42b184c364a8cf8ba6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb9565ad70b422090d5cd4a7159be1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89327482288741d983b7b1b92ea47c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec5bc9f8e0c4de1ac597007f453f721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd55b3f999a4382b7d5c2369ab227af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9220130c15234966a482217b113e47cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate embeddings (vectors) for each headline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-distilroberta-v1')\n",
    "headline_vectors = [ model.encode(sentence) for sentence in result_df['headline']]\n",
    "#check how many dimensions in a single vector \n",
    "headline_vectors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Connect to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to redis\n"
     ]
    }
   ],
   "source": [
    "#connect to redis\n",
    "\n",
    "from redis import Redis\n",
    "import redisearch\n",
    "\n",
    "host = 'vecsim'\n",
    "port = 6379\n",
    "redis_conn = Redis(host = host, port = port)\n",
    "print ('Connected to redis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Utility functions to load data into Redis \n",
    "We'll be loading into a \"hash\" structure (a table-like structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load articles into redis hash\n",
    "import numpy as np\n",
    "def load_vectors(client:Redis, headlines_df, vector_data,vector_field_name):\n",
    "    #pipeline the 300 articles in one go\n",
    "    p = client.pipeline(transaction=False)\n",
    "    for index, row in headlines_df.iterrows():    \n",
    "        #hash key\n",
    "        key='article:'+ str(index)\n",
    "        #hash fields\n",
    "        headline=row['headline']\n",
    "        url=row['url']\n",
    "        publisher=row['publisher']\n",
    "        date=row['date']\n",
    "        label=row['label']\n",
    "        score=row['score']\n",
    "        headline_vector = vector_data[index].astype(np.float32).tobytes()\n",
    "        headline_data_mapping ={'headline':headline,'url':url,'publisher':publisher,'label':label,'score':score, vector_field_name:headline_vector}\n",
    "        \n",
    "        p.hset(key,mapping=headline_data_mapping)\n",
    "    p.execute()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. More Utility Functions to Define vector indexes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Functions to Create Indexes on Vector field\n",
    "\n",
    "def create_bf_index (redis_conn,index_name,vector_field_name,number_of_vectors, vector_dimensions=768, distance_metric='L2'):\n",
    "    bf_index = redisearch.Client(index_name, conn=redis_conn)\n",
    "    bf_index.redis.execute_command(\"FT.CREATE\", index_name, \"SCHEMA\",vector_field_name, \"VECTOR\", \"FLAT\", \"8\", \"TYPE\", \"FLOAT32\", \"DIM\", vector_dimensions, \"DISTANCE_METRIC\", distance_metric, \"INITIAL_CAP\", number_of_vectors)\n",
    "    return bf_index\n",
    "\n",
    "def create_hnsw_index (redis_conn,index_name,vector_field_name,number_of_vectors, vector_dimensions=768, distance_metric='L2',M=40,EF=200):\n",
    "    hnsw_index = redisearch.Client(index_name, conn=redis_conn)\n",
    "    hnsw_index.redis.execute_command(\"FT.CREATE\", index_name, \"SCHEMA\", vector_field_name, \"VECTOR\", \"HNSW\", \"12\", \"TYPE\", \"FLOAT32\", \"DIM\", vector_dimensions, \"DISTANCE_METRIC\", distance_metric,  \"INITIAL_CAP\", number_of_vectors, \"M\", M, \"EF\", EF)\n",
    "    return hnsw_index\n",
    "\n",
    "def delete_index(vector_index):\n",
    "    delete_data(vector_index.redis)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Utility Functions to Query a vector index in Redis\n",
    "One function to query brute-force index and another to query an HNSW index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Functions to Perform Similarity Search\n",
    "\n",
    "def find_similar_bf(headline_q, query_encoder, vector_index,vector_field_name, topK=5):\n",
    "    #vectorize the query\n",
    "    query_vector = query_encoder.encode(headline_q).astype(np.float32).tobytes()\n",
    "    #prepare the query\n",
    "    q = redisearch.Query(f'(*)=>[TOP_K $K @{vector_field_name} $BLOB AS vector_score]').sort_by('vector_score').paging(0,topK).return_fields('vector_score','score','headline','label')\n",
    "    #Execute the query\n",
    "    results = vector_index.search(q, query_params = {'BLOB': query_vector, 'K':topK})\n",
    "    return results \n",
    "\n",
    "def find_similar_hnsw(headline_q, query_encoder, vector_index,vector_field_name, topK=5,EF=5):\n",
    "    #vectorize the query\n",
    "    query_vector = query_encoder.encode(headline_q).astype(np.float32).tobytes()\n",
    "    #prepare the query\n",
    "    q = redisearch.Query(f'(*)=>[TOP_K $K @{vector_field_name} $BLOB EF_RUNTIME $EF AS vector_score]').sort_by('vector_score').paging(0,topK).return_fields('vector_score','score','headline','label')    #Execute the query\n",
    "    results = vector_index.search(q, query_params = {'BLOB': query_vector, 'K':topK, 'EF':EF})\n",
    "    return results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Finally Load the Data into Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brute-Force - Load and Index article & vector Data\n",
    "NUMBER_ARTICLES = 300\n",
    "VECTOR_FIELD_NAME = 'headline_vector'\n",
    "redis_conn.flushall()\n",
    "bf_index = create_bf_index(redis_conn,'bf_index',VECTOR_FIELD_NAME,NUMBER_ARTICLES,768,'L2')\n",
    "load_vectors(bf_index.redis,result_df,headline_vectors,VECTOR_FIELD_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Query for similarity on the Brute-force index\n",
    "Get Top5 most semantically similar headlines to a given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Product  found ************\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'headline_vector_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m***************Product  found ************\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#this must be a bug, I get the the headline by retrieving the \"vector score\" field!?\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheadline = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheadline_vector_score\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m doc\u001b[38;5;241m.\u001b[39mlabel)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m doc\u001b[38;5;241m.\u001b[39mid)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Document' object has no attribute 'headline_vector_score'"
     ]
    }
   ],
   "source": [
    "#query for similarity\n",
    "\n",
    "new_headline='bearish conditions ahead'\n",
    "\n",
    "results = find_similar_bf (new_headline,model,bf_index,VECTOR_FIELD_NAME,5)\n",
    "for doc in results.docs:\n",
    "    print ('***************Product  found ************')\n",
    "    #this must be a bug, I get the the headline by retrieving the \"vector score\" field!?\n",
    "    print ('headline = ' + doc.headline_vector_score)\n",
    "    print ('label = ' + doc.label)\n",
    "    \n",
    "    print ('id = ' + doc.id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.docs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
