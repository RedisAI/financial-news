{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get 300 Financial News Headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "headlines_df = pd.read_csv('data/300_stock_headlines.csv')\n",
    "headlines_df.drop('Unnamed: 0.1', axis=1, inplace=True)\n",
    "headlines_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "headlines_df.reset_index()\n",
    "headlines_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate Financial Sentiment for each headline\n",
    "Using a pre-trained model fine-tuned on financial news/report data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate financial sentiment for each headline\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "nlp = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer)\n",
    "headlines = headlines_df[\"headline\"].tolist()\n",
    "\n",
    "#get financial sentiment for all headlines\n",
    "results = nlp(headlines)\n",
    "\n",
    "#show results for first 2 headlines\n",
    "print(results[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Join Financial Sentiment and Headline into a single Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put headlines and financial sentiment in 1 dataframe\n",
    "sentiment_df = pd.DataFrame(results)\n",
    "sentiment_df.reset_index()\n",
    "\n",
    "result_df = pd.concat([headlines_df, sentiment_df],axis=1)\n",
    "#show the first 5 rows \n",
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate Embeddings for each headline\n",
    "Using a HuggingFace Sentence Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate embeddings (vectors) for each headline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-distilroberta-v1')\n",
    "headline_vectors = [ model.encode(sentence) for sentence in result_df['headline']]\n",
    "#check how many dimensions in a single vector \n",
    "headline_vectors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Connect to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "#connect to redis\n",
    "host = 'vecsim'\n",
    "port = 6379\n",
    "redis_conn = redis.Redis(host = host, port = port)\n",
    "print ('Connected to redis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Utility functions to load data into Redis \n",
    "We'll be loading into a \"hash\" structure (a table-like structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load articles into redis hash\n",
    "import numpy as np\n",
    "def load_vectors(client:redis.Redis, headlines_df, vector_data,vector_field_name):\n",
    "    #pipeline the 300 articles in one go\n",
    "    p = client.pipeline(transaction=False)\n",
    "    for index, row in headlines_df.iterrows():    \n",
    "        #hash key\n",
    "        key='article:'+ str(index)\n",
    "        #hash fields\n",
    "        headline=row['headline']\n",
    "        url=row['url']\n",
    "        publisher=row['publisher']\n",
    "        date=row['date']\n",
    "        label=row['label']\n",
    "        score=row['score']\n",
    "        headline_vector = vector_data[index].astype(np.float32).tobytes()\n",
    "        headline_data_mapping ={'headline':headline,'url':url,'publisher':publisher,'label':label,'score':score, vector_field_name:headline_vector}\n",
    "        \n",
    "        p.hset(key,mapping=headline_data_mapping)\n",
    "    p.execute()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Utility Functions to Define vector indexes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Functions to Create Indexes on Vector field\n",
    "\n",
    "def create_flat_index (redis_conn,vector_field_name,number_of_vectors, vector_dimensions=768, distance_metric='COSINE'):\n",
    "    create_command =  [\"FT.CREATE\", \"idx\", \"SCHEMA\",\"publisher\",\"TAG\",\"headline\",\"TEXT\",\"label\",\"TAG\",\"score\",\"NUMERIC\"]\n",
    "    create_command += [\"headline_vector\", \"VECTOR\", \"FLAT\", \"8\", \n",
    "                        \"TYPE\", \"FLOAT32\", \n",
    "                        \"DIM\", str(vector_dimensions), \n",
    "                        \"DISTANCE_METRIC\", str(distance_metric), \n",
    "                        \"INITIAL_CAP\", 300]\n",
    "    redis_conn.execute_command(*create_command)\n",
    "\n",
    "def create_hnsw_index (redis_conn,vector_field_name,number_of_vectors, vector_dimensions, distance_metric='COSINE',M=40,EF=200):\n",
    "    \n",
    "    create_command =  [\"FT.CREATE\", \"idx\", \"SCHEMA\",\"publisher\",\"TAG\",\"headline\",\"TEXT\",\"label\",\"TAG\",\"score\",\"NUMERIC\"]\n",
    "    create_command += [\"headline_vector\", \"VECTOR\", \"HNSW\", \"12\", \n",
    "                        \"TYPE\", \"FLOAT32\", \n",
    "                        \"DIM\", str(vector_dimensions), \n",
    "                        \"DISTANCE_METRIC\", str(distance_metric), \n",
    "                        \"INITIAL_CAP\", 300,\n",
    "                        \"M\", M, \n",
    "                        \"EF_CONSTRUCTION\", EF]\n",
    "    \n",
    "    redis_conn.execute_command(*create_command)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Load and Index data (HNSW Vector Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_ARTICLES = 300\n",
    "VECTOR_FIELD_NAME = 'headline_vector'\n",
    "DISTANCE_METRIC = 'COSINE'\n",
    "DIMENSIONS = 768\n",
    "\n",
    "redis_conn.flushall()\n",
    "create_hnsw_index(redis_conn,VECTOR_FIELD_NAME,NUMBER_ARTICLES,DIMENSIONS,DISTANCE_METRIC)\n",
    "load_vectors(redis_conn,result_df,headline_vectors,VECTOR_FIELD_NAME)\n",
    "print ('300 News Articles loaded and indexed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. A simple FT.SEARCH (without vector similarity)\n",
    "## Get 5 articles published by 'GuruFocus' \n",
    "\n",
    "FT.SEARCH QUERY = @publisher:{GuruFocus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from redis.commands.search import Search\n",
    "from redis.commands.search.query import Query\n",
    "\n",
    "\n",
    "q = Query(f'@publisher:{{GuruFocus}}').return_fields('headline','publisher','label','score').paging(0,5)\n",
    "docs = redis_conn.ft().search(q).docs\n",
    "\n",
    "for doc in docs:\n",
    "    print (\"********DOCUMENT: \" + str(doc.id) + ' ********')\n",
    "    print(doc.headline)\n",
    "    print(doc.publisher)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. A simple FT.SEARCH (only vector similarity)\n",
    "## Get top 4 articles with healines semantically similar to \"downturn in european markets\" \n",
    "\n",
    "FT.SEARCH QUERY = *=>[KNN 4 @headline_vector $QUERY_BLOB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query for similarity\n",
    "\n",
    "user_query='downturn in european markets'\n",
    "e = model.encode(user_query)\n",
    "\n",
    "q = Query(f'*=>[KNN $K @headline_vector $BLOB]').return_fields('headline','publisher','label','score').sort_by('__headline_vector_score').paging(0,4)\n",
    "\n",
    "#parameters to be passed into search\n",
    "params_dict = {\"K\": 4, \"BLOB\": e.tobytes()}\n",
    "docs = redis_conn.ft().search(q,params_dict).docs\n",
    "\n",
    "for doc in docs:\n",
    "    print (\"********DOCUMENT: \" + str(doc.id) + ' ********')\n",
    "    print(doc.headline)\n",
    "    print(doc.publisher)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. A Hybrid Query FT.SEARCH (vector and non-vector search criteria)\n",
    "## Get top 5 articles with \n",
    "- headlines semantically similar to \"downturn in european markets\"  AND\n",
    "- negative sentiment (label=negative)\n",
    "\n",
    "FT.SEARCH QUERY = (@label:{negative})=>[KNN 5 @headline_vector $QUERY_BLOB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query \n",
    "user_query='downturn in european markets'\n",
    "e = model.encode(user_query)\n",
    "\n",
    "#build query\n",
    "q = Query(f' (@label:{{negative}})=>[KNN $K @headline_vector $BLOB]').return_fields('headline','publisher','label','score').sort_by('__headline_vector_score').paging(0,5)\n",
    "\n",
    "#parameters to be injected into query\n",
    "params_dict = {\"K\": 5, \"BLOB\": e.tobytes()}\n",
    "\n",
    "#FT.SEARCH \n",
    "docs = redis_conn.ft().search(q,params_dict).docs\n",
    "\n",
    "for doc in docs:\n",
    "    print (\"********DOCUMENT: \" + str(doc.id) + ' ********')\n",
    "    print(doc.headline)\n",
    "    print(doc.publisher)\n",
    "    print(doc.label)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Another Hybrid Query FT.SEARCH (vector and non-vector search criteria)\n",
    "## Get top 5 articles with \n",
    "- headlines semantically similar to \"downturn in european markets\"  AND\n",
    "- negative sentiment (label=negative)\n",
    "- containing the word **'Agilent'** **ON any text fields** on the index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query for similarity\n",
    "\n",
    "user_query='downturn in european markets'\n",
    "e = model.encode(user_query)\n",
    "\n",
    "q = Query(f'(Agilent @label:{{negative}})=>[KNN $K @headline_vector $BLOB]').return_fields('headline','publisher','label','score').sort_by('__headline_vector_score').paging(0,5)\n",
    "\n",
    "#parameters to be passed into search\n",
    "params_dict = {\"K\": 5, \"BLOB\": e.tobytes()}\n",
    "docs = redis_conn.ft().search(q,params_dict).docs\n",
    "\n",
    "for doc in docs:\n",
    "    print (\"********DOCUMENT: \" + str(doc.id) + ' ********')\n",
    "    print(doc.headline)\n",
    "    print(doc.publisher)\n",
    "    print(doc.label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Load and Index data (FLAT Vector Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_ARTICLES = 300\n",
    "VECTOR_FIELD_NAME = 'headline_vector'\n",
    "DISTANCE_METRIC = 'COSINE'\n",
    "DIMENSIONS = 768\n",
    "\n",
    "redis_conn.flushall()\n",
    "create_flat_index(redis_conn,VECTOR_FIELD_NAME,NUMBER_ARTICLES,DIMENSIONS,DISTANCE_METRIC)\n",
    "load_vectors(redis_conn,result_df,headline_vectors,VECTOR_FIELD_NAME)\n",
    "print ('300 News Articles loaded and indexed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Another Hybrid Query FT.SEARCH (vector and non-vector search criteria)\n",
    "## Get top 5 articles with \n",
    "- headlines semantically similar to \"downturn in european markets\"  AND\n",
    "- negative sentiment (label=negative)\n",
    "- containing the word **'Agilent'** **ON any text fields** on the index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query='downturn in european markets'\n",
    "e = model.encode(user_query)\n",
    "\n",
    "q = Query(f'(Agilent @label:{{negative}})=>[KNN $K @headline_vector $BLOB]').return_fields('headline','publisher','label','score').sort_by('__headline_vector_score').paging(0,5)\n",
    "\n",
    "#parameters to be passed into search\n",
    "params_dict = {\"K\": 5, \"BLOB\": e.tobytes()}\n",
    "docs = redis_conn.ft().search(q,params_dict).docs\n",
    "\n",
    "for doc in docs:\n",
    "    print (\"********DOCUMENT: \" + str(doc.id) + ' ********')\n",
    "    print(doc.headline)\n",
    "    print(doc.publisher)\n",
    "    print(doc.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
